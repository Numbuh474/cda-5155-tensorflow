{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Copy of test_notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Numbuh474/cda-5155-tensorflow/blob/master/Copy_of_test_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HE6w2JzF4ZA",
        "colab_type": "code",
        "outputId": "bf8871e9-c4c8-48a6-fc7d-af7d1c680f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# Clone the entire repo.\n",
        "%cd /content\n",
        "%rm -rf \"cloned-repo\"\n",
        "!git clone -l -s https://github.com/indera-shsp/cda-5155-tensorflow.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 687, done.\u001b[K\n",
            "remote: Counting objects: 100% (687/687), done.\u001b[K\n",
            "remote: Compressing objects: 100% (670/670), done.\u001b[K\n",
            "remote: Total 687 (delta 18), reused 679 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (687/687), 6.67 MiB | 25.78 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "/content/cloned-repo\n",
            "config\t  output\t   requirements.txt    test_notebook.ipynb\n",
            "logs\t  parse_images.py  sample_output_2.md  train_01\n",
            "Makefile  README.md\t   sample_output.md    utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKSbwW-IE4vl",
        "colab_type": "code",
        "outputId": "b08475d4-ad01-48af-9f1f-5f549289e8d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# from openlocationcode import openlocationcode as olc\n",
        "# olc.encode(47.365590, 8.524997)\n",
        "#'8FVC9G8F+6X'\n",
        "\n",
        "# @see datasets https://github.com/tensorflow/datasets\n",
        "# @see https://stackoverflow.com/questions/44416764/loading-folders-of-images-in-tensorflow\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import time\n",
        "default_timeit_steps = 1000\n",
        "\n",
        "# data_dir = '/Volumes/dev/cda-5155-tensorflow/output_256px_grouped_grayscale/set_1'\n",
        "data_dir = '/content/cloned-repo/output/set_all'\n",
        "validation_dir = '/content/cloned-repo/output/set_all'\n",
        "\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "\n",
        "print('Using tensorflow version: {}'.format(tf.__version__))\n",
        "print('Using input dir: {} with {} images'.format(data_dir, image_count))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Using tensorflow version: 2.0.0\n",
            "Using input dir: /content/cloned-repo/output/set_all with 582 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU5TyISyE4v5",
        "colab_type": "code",
        "outputId": "8287c889-044f-4cba-cc35-1160f9b581f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') ])\n",
        "CLASS_NAMES\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['76XVJMX2+CQFP4', '76XVJMX3+FP9FW', '76XVJMX3+C3P3M',\n",
              "       '76XVJMX4+2GW5R', '76XVJMX2+9CGRG', '76XVJMX2+FR826',\n",
              "       '76XVJMX4+W47W5', '76XVJMX4+XQ9HC', '76XVJMX3+CPQHJ',\n",
              "       '76XVJMX3+9QC65', '76XVMM25+J7M76', '76XVJMW3+JVRWJ',\n",
              "       '76XVJMX3+C8QQQ', '76XVJMX3+9HXC2', '76XVMM25+63R4V',\n",
              "       '76XVJMX2+G4Q7X', '76XVJMX3+FJFV5', '76XVJMX3+9GHPW',\n",
              "       '76XVJMX5+W4424', '76XVJMX3+7JXHG', '76XVJMX4+M47M9',\n",
              "       '76XVMM25+Q2P34', '76XVMM24+QHV37', '76XVJMX3+877FW',\n",
              "       '76XVJMX4+M38V4', '76XVMM24+JF4HW', '76XVJMX4+R4V8J',\n",
              "       '76XVJMX4+R4VJR', '76XVMM24+4G5QJ', '76XVJMX4+WC77W',\n",
              "       '76XVMM25+923GM', '76XVJMX4+R4VP8', '76XVJMX4+XPHX2',\n",
              "       '76XVJMX2+CJCWQ', '76XVMM24+PV49G', '76XVMM25+84PJ2',\n",
              "       '76XVJMX3+C77RF', '76XVJMX2+9Q99G', '76XVJMX4+V4349',\n",
              "       '76XVJMX2+9VM2V', '76XVJMX4+XG5GP', '76XVJMX2+CPW45',\n",
              "       '76XVJMX4+R4VWH', '76XVJMX4+WGP67', '76XVMM24+JGX4V',\n",
              "       '76XVMM24+QJCRV', '76XVJMX4+WHR3R', '76XVMM24+3HRJ8',\n",
              "       '76XVJMX4+R4VHF', '76XVMM25+J3X49', '76XVMM24+6HQCH',\n",
              "       '76XVMM24+CJR4X', '76XVMM24+MV9R5', '76XVJMX4+XWPJH',\n",
              "       '76XVMM24+7JQVM', '76XVJMX2+FF286', '76XVJMX2+CHXXJ',\n",
              "       '76XVJMX4+R6JX4'], dtype='<U14')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MglR3M7E4wA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WibbFiW_E4wH",
        "colab_type": "code",
        "outputId": "c7ef9d5d-1d81-4499-9025-90ef4c6224ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_generator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.preprocessing.image.ImageDataGenerator at 0x7f9293b04358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT05Ux-JE4wO",
        "colab_type": "code",
        "outputId": "2f625f45-7a08-4099-8795-a302cf16758d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Define some parameters for the loader:\n",
        "\n",
        "epochs = 8\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "IMG_HEIGHT = 192\n",
        "IMG_WIDTH = 256\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
        "print('STEPS_PER_EPOCH: {}'.format(STEPS_PER_EPOCH))\n",
        "\n",
        "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
        "                                                     batch_size=BATCH_SIZE,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary'\n",
        "                                                    )\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(directory=validation_dir,\n",
        "                                                              batch_size=BATCH_SIZE,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              # classes = list(CLASS_NAMES)\n",
        "                                                              class_mode='binary'\n",
        "                                                             )\n",
        "\n",
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STEPS_PER_EPOCH: 5.0\n",
            "Found 582 images belonging to 58 classes.\n",
            "Found 582 images belonging to 58 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhd5zpF3E4wV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_batch, label_batch = next(train_data_gen)\n",
        "# show_batch(image_batch, label_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxTwsAmfE4wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj7xDlZWE4wh",
        "colab_type": "code",
        "outputId": "df5da8da-f651-4c47-a5a9-af8d96f54e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'/content/cloned-repo/output/set_all/76XVJMX4+WGP67/thumb_0224_lat_29.6498319_lon_-82.3436839.jpg'\n",
            "b'/content/cloned-repo/output/set_all/76XVJMX4+R4VHF/thumb_0244_lat_29.6496129_lon_-82.344693.jpg'\n",
            "b'/content/cloned-repo/output/set_all/76XVJMX2+CHXXJ/thumb_0348_lat_29.648623_lon_-82.3485069.jpg'\n",
            "b'/content/cloned-repo/output/set_all/76XVJMX4+WC77W/thumb_0230_lat_29.649784_lon_-82.343957.jpg'\n",
            "b'/content/cloned-repo/output/set_all/76XVJMX3+FJFV5/thumb_0517_lat_29.648695_lon_-82.345955.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCDDMi_zE4wq",
        "colab_type": "code",
        "outputId": "148382ac-974f-4d21-9977-7d77cd2937d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] == CLASS_NAMES\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  # return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "  return img\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n",
        "\n",
        "print('AUTOTUNE: {}'.format(AUTOTUNE))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUTOTUNE: -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSPbhJreE4wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00L7fk6kE4w3",
        "colab_type": "code",
        "outputId": "927ca994-9dd9-4791-c723-3aba0f7defbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "for image, label in labeled_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (192, 256, 3)\n",
            "Label:  [False False False False False False False False False False False False\n",
            " False False False  True False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koVng-UkE4w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  # This is a small dataset, only load it once, and keep it in memory.\n",
        "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "  # fit in memory.\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ajg94GdE4xG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# speedup loading\n",
        "# train_ds = prepare_for_training(labeled_ds)\n",
        "# image_batch, label_batch = next(iter(train_ds))\n",
        "# show_batch(image_batch.numpy(), label_batch.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7IZB0xFE4xM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def timeit(ds, steps=default_timeit_steps):\n",
        "  start = time.time()\n",
        "  it = iter(ds)\n",
        "  for i in range(steps):\n",
        "    batch = next(it)\n",
        "    if i%10 == 0:\n",
        "      print('.',end='')\n",
        "  print()\n",
        "  end = time.time()\n",
        "\n",
        "  duration = end-start\n",
        "  print(\"{} batches: {} s\".format(steps, duration))\n",
        "  print(\"{:0.5f} Images/s\".format(BATCH_SIZE*steps/duration))\n",
        "\n",
        "\n",
        "# timeit(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U9ccsO7E4xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# timeit(train_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAYL0WuYE4xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter\n",
        "# type(labeled_ds.)\n",
        "\n",
        "# image_paths, labels = labeled_ds # load_base_data(...)\n",
        "# epoch_size = len(image_paths)\n",
        "# image_paths = tf.convert_to_tensor(image_paths, dtype=tf.string)\n",
        "# labels = tf.convert_to_tensor(labels)\n",
        "\n",
        "# dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "\n",
        "#type(train_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ5mSFPaE4xX",
        "colab_type": "code",
        "outputId": "8dd7b560-4828-404d-aab6-4ac83dcdafe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_ds, _ = next(train_data_gen)\n",
        "\n",
        "len(validation_ds)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94VBXIFsE4xb",
        "colab_type": "code",
        "outputId": "26217aa0-4429-4168-f9ac-9378bd0e15fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 192, 256, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 96, 128, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 96, 128, 32)       4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 48, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 48, 64, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 24, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 49152)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               25166336  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 25,190,433\n",
            "Trainable params: 25,190,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvaANOnqE4xf",
        "colab_type": "code",
        "outputId": "239733c6-35cd-49e4-c2a5-d4c809124476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(validation_ds)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyu8An_6E4xn",
        "colab_type": "code",
        "outputId": "3eb2847d-1492-4b40-f695-9a696dbe2cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "\n",
        "total_train = 582 # len(train_ds)\n",
        "total_val =  len(val_data_gen)\n",
        "\n",
        "print('total_train: {}, total_val: {}'.format(total_train, total_val))\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // BATCH_SIZE,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=1 # total_val // BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_train: 582, total_val: 5\n",
            "Epoch 1/8\n",
            "4/4 [==============================] - 32s 8s/step - loss: -269.8649 - accuracy: 0.0022 - val_loss: -395.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/8\n",
            "4/4 [==============================] - 36s 9s/step - loss: -377.5810 - accuracy: 0.0059 - val_loss: -395.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/8\n",
            "4/4 [==============================] - 32s 8s/step - loss: -379.0375 - accuracy: 0.0044 - val_loss: -395.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/8\n",
            "4/4 [==============================] - 32s 8s/step - loss: -369.5105 - accuracy: 0.0022 - val_loss: -395.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/8\n",
            "4/4 [==============================] - 32s 8s/step - loss: -370.6023 - accuracy: 0.0022 - val_loss: -395.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/8\n",
            "4/4 [==============================] - 30s 8s/step - loss: -365.3871 - accuracy: 0.0022 - val_loss: -395.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/8\n",
            "4/4 [==============================] - 31s 8s/step - loss: -386.3390 - accuracy: 0.0066 - val_loss: -395.0705 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/8\n",
            "4/4 [==============================] - 36s 9s/step - loss: -350.4184 - accuracy: 0.0000e+00 - val_loss: -395.0705 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2ltGbjOE4xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEo7dG09E4x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCSK0CpfE4yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}